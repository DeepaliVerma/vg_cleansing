{
 "metadata": {
  "name": "",
  "signature": "sha256:9851746f9ee61a6ad6ed73dbfe0c974b62854992914d64a47d609dd877bc8a7f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- To read data from the JSON file and remove the annotations with wrong spelling."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import import_data as imported_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "image data length: 108077\n",
        "relationship data length: 108077"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0 images processed, 30 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 images processed, 17927 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000 images processed, 33231 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000 images processed, 45014 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000 images processed, 63395 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000 images processed, 79245 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6000 images processed, 94198 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7000 images processed, 108777 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8000 images processed, 121458 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9000 images processed, 130343 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 images processed, 143734 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11000 images processed, 164453 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000 images processed, 188407 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13000 images processed, 215554 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000 images processed, 241383 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000 images processed, 264694 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000 images processed, 285498 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000 images processed, 305438 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000 images processed, 327446 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19000 images processed, 349464 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000 images processed, 371841 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21000 images processed, 391910 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22000 images processed, 410411 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23000 images processed, 427529 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24000 images processed, 445905 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000 images processed, 462789 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26000 images processed, 481220 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27000 images processed, 498390 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "28000 images processed, 512966 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29000 images processed, 526777 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000 images processed, 543516 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "31000 images processed, 559238 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32000 images processed, 576648 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33000 images processed, 592752 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "34000 images processed, 608954 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35000 images processed, 626475 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000 images processed, 643686 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37000 images processed, 662244 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38000 images processed, 678559 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39000 images processed, 693683 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000 images processed, 709698 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41000 images processed, 728332 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42000 images processed, 746444 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "43000 images processed, 765028 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44000 images processed, 782783 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45000 images processed, 801131 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "46000 images processed, 818470 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47000 images processed, 835046 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000 images processed, 852160 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "49000 images processed, 869642 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000 images processed, 887229 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "51000 images processed, 903333 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "52000 images processed, 920759 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "53000 images processed, 937959 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "54000 images processed, 953626 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "55000 images processed, 971250 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "56000 images processed, 988965 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "57000 images processed, 1008501 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "58000 images processed, 1026844 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "59000 images processed, 1044188 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000 images processed, 1062418 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "61000 images processed, 1080840 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "62000 images processed, 1100234 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "63000 images processed, 1121418 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "64000 images processed, 1142114 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "65000 images processed, 1161029 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "66000 images processed, 1178536 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "67000 images processed, 1196949 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "68000 images processed, 1214281 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "69000 images processed, 1232267 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "70000 images processed, 1248892 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "71000 images processed, 1267338 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "72000 images processed, 1285950 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "73000 images processed, 1302946 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "74000 images processed, 1322416 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "75000 images processed, 1343239 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "76000 images processed, 1364315 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "77000 images processed, 1386019 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "78000 images processed, 1407226 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "79000 images processed, 1422843 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "80000 images processed, 1435846 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "81000 images processed, 1447989 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "82000 images processed, 1461374 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "83000 images processed, 1479569 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "84000 images processed, 1498238 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "85000 images processed, 1515033 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "86000 images processed, 1529869 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "87000 images processed, 1540882 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "88000 images processed, 1550570 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "89000 images processed, 1561763 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "90000 images processed, 1576494 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "91000 images processed, 1592577 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "92000 images processed, 1606200 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "93000 images processed, 1622886 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "94000 images processed, 1640080 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "95000 images processed, 1656550 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "96000 images processed, 1672478 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "97000 images processed, 1689203 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "98000 images processed, 1707387 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "99000 images processed, 1727686 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100000 images processed, 1746967 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "101000 images processed, 1768817 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102000 images processed, 1790642 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "103000 images processed, 1806991 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "104000 images processed, 1824176 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "105000 images processed, 1848665 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "106000 images processed, 1866533 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "107000 images processed, 1880823 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "108000 images processed, 1894646 relationships"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Currently, we have 1895709 relationship tuples\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Currently, we have 21724 predicates\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filter the loaded data\n",
      "----------------------------------\n",
      "\n",
      "After loading the data, we should filter the data to meet our requirement. \n",
      "\n",
      "Firstly, we define some functions to view the annotations:\n",
      "\n",
      "`print_phrase_based_on_predicate` helps to print the related visual phrase with corresponding predicate\n",
      "`output_predicate_list` is to output the list of existing predicate\n",
      "`read_obj_list_from` is read object categories from the \\*.txt list file\n",
      "    - Different alias of same categories are in the same line divided with ' '(space)\n",
      "    - Different categories are in different lines\n",
      "`normalize_annotation` helps merge the alias of the same category (Use the first name as the category name)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_phrase_based_on_predicate(imported_data, predicate):\n",
      "    relationship_num = len(imported_data.predicate_dataset[predicate]['index'])\n",
      "    print('Total: {} relationship items in [{}]\\n'.format(relationship_num, predicate))\n",
      "    for r_id, relationship_item in enumerate(imported_data.predicate_dataset[predicate]['index']):\n",
      "        print('[{}]: [{}]-[{}]-[{}]\\n'.format(predicate, \\\n",
      "                                              imported_data.predicate_dataset[predicate]['subject'][r_id], \\\n",
      "                                              predicate, \\\n",
      "                                              imported_data.predicate_dataset[predicate]['object'][r_id]))\n",
      "        if r_id > 200:\n",
      "            break\n",
      "def output_predicate_list(imported_data, frequency_thres):\n",
      "    output_file = '/home/ykli/predicate_list_{}.txt'.format(frequency_thres)\n",
      "    with open(output_file, 'w') as f:\n",
      "        for idx, predicate in enumerate(imported_data.predicate_dataset.keys()):\n",
      "            if imported_data.predicate_count[predicate] > frequency_thres:\n",
      "                f.write(predicate+'\\n')\n",
      "                \n",
      "def read_obj_list_from(obj_list_path):\n",
      "    pascal_categories = [];\n",
      "    with open(obj_list_path, 'r') as f:\n",
      "        for line in f:\n",
      "            pascal_categories.append(line.split())\n",
      "    return pascal_categories\n",
      "\n",
      "def normalize_annotation(relationships):\n",
      "    required_objs = read_obj_list_from('temp_data/pascal_obj_list.txt')\n",
      "    required_pred = read_obj_list_from('temp_data/predicate_25.txt')\n",
      "    for item_key in relationships:\n",
      "        im_item = relationships[item_key]\n",
      "        for r in im_item['relationships']:\n",
      "            for cat in required_objs:\n",
      "                if r['subject'] in cat:\n",
      "                    r['subject'] = cat[0]\n",
      "                if r['object'] in cat:\n",
      "                    r['object'] = cat[0]\n",
      "            for cat in required_pred:\n",
      "                if r['predicate'] in cat:\n",
      "                    r['predicate'] = cat[0]\n",
      "                    \n",
      "    return relationships"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To extract annotations of related object categories.\n",
      "---------------------------------------\n",
      "\n",
      "(By default) The function is designed for extracting the object categories within Pascal VOC. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_pascal_obj_from(obj_list_path, imported_data, predicate_select_thres = 100):\n",
      "\n",
      "    pascal_obj_categories = read_obj_list_from(obj_list_path)\n",
      "    obj_counter = np.zeros([20,1])\n",
      "    relationship_based_on_pascal = {}\n",
      "    selected_predicates = []\n",
      "    selected_objects = set()\n",
      "    for idx, predicate in enumerate(imported_data.predicate_dataset.keys()):\n",
      "        if imported_data.predicate_count[predicate] > predicate_select_thres:\n",
      "            selected_predicates.append(predicate)\n",
      "            # print('Predicate: ' + predicate + ' Added! (' + str(imported_data.predicate_count[predicate]) + ' instances)');\n",
      "            for phrase_id, pair in enumerate(imported_data.predicate_dataset[predicate]['index']):\n",
      "                # to check whether the relationship contains categories in Pascal VOC\n",
      "                flag_is_store = True\n",
      "                current_subject = imported_data.predicate_dataset[predicate]['subject'][phrase_id]\n",
      "                current_object = imported_data.predicate_dataset[predicate]['object'][phrase_id]\n",
      "                for c_idx, cate in enumerate(pascal_obj_categories):\n",
      "                    # if containing, add it to out selected annotations\n",
      "                    if current_subject in cate or current_object in cate:\n",
      "                        obj_counter[c_idx] += 1\n",
      "                        selected_objects.add(current_object)\n",
      "                        selected_objects.add(current_subject)\n",
      "                        if flag_is_store:\n",
      "                            relationship_item = {};\n",
      "                            relationship_item['object'] = imported_data.predicate_dataset[predicate]['object'][phrase_id];    \n",
      "                            relationship_item['subject'] = imported_data.predicate_dataset[predicate]['subject'][phrase_id];\n",
      "                            relationship_item['sub_box'] = imported_data.predicate_dataset[predicate]['sub_box'][phrase_id];\n",
      "                            relationship_item['obj_box'] = imported_data.predicate_dataset[predicate]['obj_box'][phrase_id];\n",
      "                            relationship_item['predicate'] = predicate;\n",
      "                            if pair[0] in relationship_based_on_pascal.keys():\n",
      "                                relationship_based_on_pascal[pair[0]]['relationships'].append(relationship_item)\n",
      "                            else:\n",
      "                                relationship_based_on_pascal[pair[0]] = {};\n",
      "                                relationship_based_on_pascal[pair[0]]['relationships'] = [relationship_item];\n",
      "                                relationship_based_on_pascal[pair[0]]['path'] = \\\n",
      "                                str(imported_data.image_data[pair[0]]['image_id']) + '.jpg'\n",
      "                                relationship_based_on_pascal[pair[0]]['width'] = imported_data.image_data[pair[0]]['width'];\n",
      "                                relationship_based_on_pascal[pair[0]]['height'] = imported_data.image_data[pair[0]]['height'];\n",
      "                            flag_is_store = False\n",
      "                            \n",
      "    print('Start normalize the annoatations(merge the some similar categories)...')\n",
      "    relationship_based_on_pascal = normalize_annotation(relationship_based_on_pascal)\n",
      "    print('Done normalization.')\n",
      "    \n",
      "    return obj_counter, relationship_based_on_pascal, selected_predicates, selected_objects\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 241
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now do it!\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pascal_obj_list_path = 'temp_data/pascal_obj_list.txt'\n",
      "obj_counter, relationship_based_on_pascal, selected_predicates, selected_objects = \\\n",
      "extract_pascal_obj_from(pascal_obj_list_path, imported_data)\n",
      "print '{} predicate and {} object categories left.'.format(len(selected_predicates), len(selected_objects))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start normalize the annoatations(merge the some similar categories)...\n",
        "Done normalization."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Further filtering\n",
      "-------------------\n",
      "\n",
      "Currently, we have the raw relationships containing the objects from Pascal VOC. \n",
      "\n",
      "- `required_objs` is the object categories we cannot remove due to the frequency\n",
      "- `required_pred` is the predicate we need"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_infrequent_cat(cat_freq, freq_thres):\n",
      "    for item in cat_freq:\n",
      "        if cat_freq[item] < freq_thres:\n",
      "            print('[{}]: {}\\n'.format(item, cat_freq[item]))\n",
      "\n",
      "def expand_obj_list(obj_list):\n",
      "    expanded_obj_list = []\n",
      "    for cat in obj_list:\n",
      "        for item in cat:\n",
      "            expanded_obj_list.append(item)\n",
      "    return expanded_obj_list\n",
      "\n",
      "def filter_cat_keys(freq_dict, freq_thres):\n",
      "    for key in freq_dict.keys():\n",
      "        if freq_dict[key] < freq_thres:\n",
      "            freq_dict.pop(key)\n",
      "    # print('{} categories left...'.format(len(freq_dict.keys())))\n",
      "    return freq_dict.keys()\n",
      "\n",
      "\n",
      "def stat_the_freq(relationships):\n",
      "    freq_obj = {}\n",
      "    freq_pred = {}\n",
      "    for image in relationships.values():\n",
      "        for r_id, relationship_item in enumerate(image['relationships']):\n",
      "            temp_sub = relationship_item['subject']\n",
      "            temp_obj = relationship_item['object']\n",
      "            temp_predicate = relationship_item['predicate']\n",
      "            if temp_sub in freq_obj.keys():\n",
      "                freq_obj[temp_sub] += 1\n",
      "            else:\n",
      "                freq_obj[temp_sub] = 1\n",
      "            if temp_obj in freq_obj.keys():\n",
      "                freq_obj[temp_obj] += 1\n",
      "            else:\n",
      "                freq_obj[temp_obj] = 1    \n",
      "            if temp_predicate in freq_pred.keys():\n",
      "                freq_pred[temp_predicate] += 1\n",
      "            else:\n",
      "                freq_pred[temp_predicate] = 1    \n",
      "            \n",
      "    return freq_obj, freq_pred\n",
      "\n",
      "def filter_cat(relationships, freq_thres_obj = 0, freq_thres_pred = 0):\n",
      "    print 'Frequency threshold for object: {}'.format(freq_thres_obj)\n",
      "    print 'Frequency threshold for predicate: {}\\n'.format(freq_thres_pred)\n",
      "    required_objs = expand_obj_list(read_obj_list_from('temp_data/pascal_obj_list.txt'))\n",
      "    required_pred = expand_obj_list(read_obj_list_from('temp_data/predicate_25.txt'))\n",
      "    print 'Counting the obj/pred frequency...\\n'\n",
      "    freq_obj, freq_pred = stat_the_freq(relationships)\n",
      "    print 'Done counting!\\nStart Filtering...\\n'\n",
      "    new_obj_keys = filter_cat_keys(freq_obj, freq_thres_obj)\n",
      "    new_pred_keys = filter_cat_keys(freq_pred, freq_thres_pred)\n",
      "    im_to_del = [];\n",
      "    for im_key in relationships.keys():\n",
      "        image = relationships[im_key]\n",
      "        item_to_remove = []\n",
      "        for r_id, relationship_item in enumerate(image['relationships']):\n",
      "            temp_sub = relationship_item['subject']\n",
      "            temp_obj = relationship_item['object']\n",
      "            temp_predicate = relationship_item['predicate']\n",
      "            if ((temp_sub in new_obj_keys) or (temp_sub in required_objs)) and \\\n",
      "                ((temp_obj in new_obj_keys) or (temp_obj in required_objs)) and \\\n",
      "                ((temp_predicate in new_pred_keys) and (temp_predicate in required_pred)):\n",
      "                pass\n",
      "            else: \n",
      "                item_to_remove.append(r_id)\n",
      "        image['relationships'] = [r_item for r_id, r_item in enumerate(image['relationships']) if r_id not in item_to_remove]      \n",
      "        if  len(image['relationships']) == 0:\n",
      "            im_to_del.append(im_key)\n",
      "    print 'Start deleting images...({}/{} to delete)'.format(len(im_to_del), len(relationships.keys()))\n",
      "    for key in im_to_del:\n",
      "        relationships.pop(key)\n",
      "    print 'Done filtering!\\n'\n",
      "    return relationships"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set_freq_thres_obj = 300\n",
      "set_freq_thres_pred = 500\n",
      "filtered_relationships = filter_cat(relationship_based_on_pascal, set_freq_thres_obj, set_freq_thres_pred)\n",
      "freq_obj, freq_pred = stat_the_freq(filtered_relationships)\n",
      "print('Object category number: {}'.format(len(freq_obj.keys())))\n",
      "print('Predicate category number: {}'.format(len(freq_pred.keys())))\n",
      "# find_infrequent_cat(freq_obj, set_freq_thres_obj)\n",
      "# find_infrequent_cat(freq_pred, set_freq_thres_pred)\n",
      "print('Remaining Images: {}\\n'.format(len(filtered_relationships)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Frequency threshold for object: 300\n",
        "Frequency threshold for predicate: 500\n",
        "\n",
        "Counting the obj/pred frequency...\n",
        "\n",
        "Done counting!\n",
        "Start Filtering...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Start deleting images...(41609/58475 to delete)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done filtering!\n",
        "\n",
        "Object category number: 59"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Predicate category number: 15\n",
        "Remaining Images: 16866\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relationship_based_on_pascal[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 270,
       "text": [
        "{'height': 600, 'path': '6.jpg', 'relationships': [], 'width': 800}"
       ]
      }
     ],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_obj, freq_pred = stat_the_freq(filtered_relationships)\n",
      "instances_num = sum(freq_pred.values())\n",
      "print('Object category number: {}'.format(len(freq_obj.keys())))\n",
      "print('Predicate category number: {}'.format(len(freq_pred.keys())))\n",
      "print('Total number of images: {}'.format(len(filtered_relationships)))\n",
      "print('Total number of instances: {} ({} instances/im)'.format(instances_num, instances_num/len(filtered_relationships)))\n",
      "\n",
      "\n",
      "print('=========== object categories ===========')\n",
      "for key in freq_obj.keys():\n",
      "    print('[{}]: {}'.format(key, freq_obj[key]))\n",
      "print('=========================================')\n",
      "\n",
      "print('=========== predicate categories ===========')\n",
      "for key in freq_pred.keys():\n",
      "    print('[{}]: {}'.format(key, freq_pred[key]))\n",
      "print('=========================================')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Object category number: 59\n",
        "Predicate category number: 15\n",
        "Total number of images: 16866\n",
        "Total number of instances: 37431 (2 instances/im)\n",
        "=========== object categories ===========\n",
        "[bicycle]: 939\n",
        "[skateboard]: 315\n",
        "[fence]: 366\n",
        "[pant]: 1333\n",
        "[wall]: 337\n",
        "[shirt]: 2719\n",
        "[pole]: 403\n",
        "[street]: 1378\n",
        "[shoe]: 690\n",
        "[tvmonitor]: 115\n",
        "[chair]: 1578\n",
        "[beach]: 673\n",
        "[girl]: 307\n",
        "[boat]: 840\n",
        "[ground]: 634\n",
        "[sheep]: 1092\n",
        "[helmet]: 983\n",
        "[horse]: 2878\n",
        "[motorbike]: 1683\n",
        "[bag]: 373\n",
        "[people]: 594\n",
        "[sky]: 1126\n",
        "[bench]: 691\n",
        "[elephant]: 323\n",
        "[hat]: 1175\n",
        "[bird]: 1128\n",
        "[plate]: 303\n",
        "[woman]: 1240\n",
        "[umbrella]: 959\n",
        "[aeroplane]: 1201\n",
        "[glove]: 383\n",
        "[track]: 478\n",
        "[bus]: 933\n",
        "[water]: 696\n",
        "[glass]: 485\n",
        "[train]: 1707\n",
        "[collar]: 653\n",
        "[sofa]: 190\n",
        "[sidewalk]: 1144\n",
        "[diningtable]: 1784\n",
        "[man]: 3193\n",
        "[building]: 576\n",
        "[short]: 589\n",
        "[surfboard]: 492\n",
        "[cow]: 1422\n",
        "[car]: 2030\n",
        "[tree]: 785\n",
        "[dog]: 2162\n",
        "[bed]: 477\n",
        "[cat]: 1241\n",
        "[jacket]: 1339\n",
        "[person]: 18584\n",
        "[ski_pole]: 328\n",
        "[bottle]: 528\n",
        "[coat]: 528\n",
        "[jean]: 614\n",
        "[grass]: 2038\n",
        "[road]: 728\n",
        "[ski]: 379\n",
        "=========================================\n",
        "=========== predicate categories ===========\n",
        "[stand_on]: 1570\n",
        "[lay_on]: 677\n",
        "[wear_a]: 11431\n",
        "[above]: 745\n",
        "[park_on]: 1416\n",
        "[fly_in]: 700\n",
        "[sit_on]: 2521\n",
        "[look_at]: 957\n",
        "[beside]: 6797\n",
        "[walk_on]: 1615\n",
        "[under]: 1576\n",
        "[carry]: 535\n",
        "[rid]: 3670\n",
        "[hold]: 2210\n",
        "[eat]: 1011\n",
        "=========================================\n"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# To output the annotations to the output_dir"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def output_annoatation(output_path, relationships):\n",
      "    with open(output_path, 'w') as f:\n",
      "        output_counter = 0;\n",
      "        for item_key in relationships:\n",
      "            im_item = relationships[item_key]\n",
      "            f.write('# {}\\n'.format(item_key)) # to output the item key\n",
      "            f.write(im_item['path'] + '\\n') # to output the image path\n",
      "            f.write('{}\\n{}\\n'.format(im_item['height'], im_item['width'])) # output the height and width\n",
      "            f.write('{}\\n'.format(len(im_item['relationships'])))\n",
      "            for r in im_item['relationships']: # output the relationship item [subject]-[predicate]-[object]-[sub_box]-[obj_box]\n",
      "                f.write(r['subject'].replace(' ', '_')) \n",
      "                f.write(' ' + r['predicate'].replace(' ', '_'))\n",
      "                f.write(' ' + r['object'].replace(' ', '_'))\n",
      "                for item in r['sub_box']:\n",
      "                    f.write(' ' + str(item))\n",
      "                for item in r['obj_box']:\n",
      "                    f.write(' ' + str(item))\n",
      "                f.write('\\n')\n",
      "            output_counter+=1\n",
      "            if output_counter%1000 == 0:\n",
      "                print('{}/{} images processed'.format(output_counter, len(relationships.keys())))\n",
      "    \n",
      "    print('Result output to: {}'.format(output_path))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_annoatation('output/relationship_with_specific_predicate_{}_{}.txt'.format(set_freq_thres_obj, set_freq_thres_pred), filtered_relationships)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000/16866 images processed\n",
        "2000/16866 images processed\n",
        "3000/16866 images processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000/16866 images processed\n",
        "5000/16866 images processed\n",
        "6000/16866 images processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7000/16866 images processed\n",
        "8000/16866 images processed\n",
        "9000/16866 images processed\n",
        "10000/16866 images processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11000/16866 images processed\n",
        "12000/16866 images processed\n",
        "13000/16866 images processed\n",
        "14000/16866 images processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000/16866 images processed\n",
        "16000/16866 images processed\n",
        "Result output to: output/relationship_with_specific_predicate_300_500.txt\n"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_predicate_list(imported_data, 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    }
   ],
   "metadata": {}
  }
 ]
}